{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForQuestionAnswering\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382072689/382072689 [00:07<00:00, 50419831.74B/s]\n",
      "100%|██████████| 109540/109540 [00:00<00:00, 4137421.07B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use  cpu\n",
      "加载模型完成\n"
     ]
    }
   ],
   "source": [
    "# tokeniser = BertTokenizer.from_pretrained(model_dir)  # Add specific options if needed\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-chinese')\n",
    "tokeniser = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    dirve ='cuda'\n",
    "else:\n",
    "    dirve ='cpu'\n",
    "print('use ',dirve)\n",
    "model.to(dirve)\n",
    "print('加载模型完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#释放内存\n",
    "# del model\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_text ['[CLS]', '明', '天', '天', '气', '怎', '么', '样', '[SEP]', '明', '天', '天', '气', '不', '错', '我', '们', '不', '如', '一', '起', '出', '去', '吧', '[SEP]']\n",
      "torch.int64\n",
      "[101, 3209, 1921, 1921, 3698, 2582, 720, 3416, 102, 3209, 1921, 1921, 3698, 679, 7231, 2769, 812, 679, 1963, 671, 6629, 1139, 1343, 1416, 102]\n",
      "tokens_tensor tensor([[ 101, 3209, 1921, 1921, 3698, 2582,  720, 3416,  102, 3209, 1921, 1921,\n",
      "         3698,  679, 7231, 2769,  812,  679, 1963,  671, 6629, 1139, 1343, 1416,\n",
      "          102]])\n",
      "segments_tensors tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])\n",
      "input_mask_tensors tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])\n",
      "batch_start_logits tensor([[-0.2314, -0.3325, -0.4691, -0.1570, -0.1176, -0.3229, -0.2685,  0.0176,\n",
      "          0.1297, -0.5480, -0.4350, -0.1237, -0.0902,  0.0382,  0.1981, -0.1992,\n",
      "         -0.2722, -0.3234, -0.3967, -0.4319, -0.5689, -0.1490, -0.4177, -0.1311,\n",
      "          0.1297]], grad_fn=<SqueezeBackward1>)\n",
      "batch_end_logits tensor([[0.5972, 0.4695, 0.5503, 0.6203, 0.3157, 0.4575, 0.5127, 0.9626, 0.2215,\n",
      "         0.7128, 0.5197, 0.4107, 0.2228, 0.4007, 0.0811, 0.7070, 0.3246, 0.6371,\n",
      "         0.5859, 0.7215, 0.6195, 1.2891, 0.7241, 0.5007, 0.2215]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "q='明天天气怎么样'\n",
    "\n",
    "context=\"\"\"\n",
    "\n",
    "明天天气不错 我们不如一起出去吧\n",
    "\"\"\"\n",
    " \n",
    "\n",
    "\n",
    "question='[CLS] '+ q + ' [SEP]'\n",
    "\n",
    "context= context+ ' [SEP]'\n",
    "\n",
    "len_line_1 = len(tokeniser.tokenize(question))\n",
    "len_line_2 = len(tokeniser.tokenize(context))\n",
    "\n",
    "\n",
    "input_mask =question + context\n",
    "\n",
    "# text = question + context\n",
    "\n",
    "#         print('text',text)\n",
    "tokenized_text = tokeniser.tokenize(input_mask)\n",
    "print('tokenized_text',tokenized_text)\n",
    "\n",
    "indexed_tokens = tokeniser.convert_tokens_to_ids(tokenized_text)\n",
    "# input_mask_tokens = tokeniser.convert_tokens_to_ids(input_mask)\n",
    "segments_ids = ([0] * len_line_1) + ([1] * len_line_2)\n",
    "input_mask_tokens = [1]*len(indexed_tokens)\n",
    "\n",
    "print(torch.long)\n",
    "print(indexed_tokens)\n",
    "\n",
    "input_mask_tensors= torch.tensor([input_mask_tokens], dtype=torch.long).to(dirve)\n",
    "tokens_tensor = torch.tensor([indexed_tokens], dtype=torch.long).to(dirve)\n",
    "segments_tensors = torch.tensor([segments_ids], dtype=torch.long).to(dirve)\n",
    "\n",
    "print('tokens_tensor',tokens_tensor)\n",
    "print('segments_tensors',segments_tensors)\n",
    "print('input_mask_tensors',input_mask_tensors)\n",
    "\n",
    "#         print('tokens_tensor',tokens_tensor)\n",
    "#         print('segments_tensors',segments_tensors)\n",
    "#这里使用模型进行预测\n",
    "batch_start_logits, batch_end_logits = model(tokens_tensor, segments_tensors,input_mask_tensors)\n",
    "print('batch_start_logits',batch_start_logits)\n",
    "print('batch_end_logits',batch_end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_indexes(logits, n_best_size):\n",
    "  \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "  index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "  print('index_and_score',index_and_score)\n",
    "\n",
    "  best_indexes = []\n",
    "  for i in range(len(index_and_score)):\n",
    "    if i >= n_best_size:\n",
    "      break\n",
    "    best_indexes.append(index_and_score[i][0])\n",
    "  return best_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.23139816522598267,\n",
       " -0.3325277268886566,\n",
       " -0.4690726101398468,\n",
       " -0.1570422649383545,\n",
       " -0.11756917834281921,\n",
       " -0.3228791654109955,\n",
       " -0.2684593200683594,\n",
       " 0.01763373613357544,\n",
       " 0.129669189453125,\n",
       " -0.5479621291160583,\n",
       " -0.4350026547908783,\n",
       " -0.12372050434350967,\n",
       " -0.09021744132041931,\n",
       " 0.03824535012245178,\n",
       " 0.1981472223997116,\n",
       " -0.1992499679327011,\n",
       " -0.27217161655426025,\n",
       " -0.32344263792037964,\n",
       " -0.39665329456329346,\n",
       " -0.43190065026283264,\n",
       " -0.5689064264297485,\n",
       " -0.14896880090236664,\n",
       " -0.4176713228225708,\n",
       " -0.13106927275657654,\n",
       " 0.12966956198215485]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = batch_start_logits[0].detach().cpu().tolist()\n",
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.597241997718811,\n",
       " 0.4694574177265167,\n",
       " 0.5503278970718384,\n",
       " 0.6202974319458008,\n",
       " 0.31571725010871887,\n",
       " 0.4575151801109314,\n",
       " 0.5127164125442505,\n",
       " 0.9626365900039673,\n",
       " 0.22147777676582336,\n",
       " 0.7128044366836548,\n",
       " 0.519715428352356,\n",
       " 0.4107130169868469,\n",
       " 0.22277796268463135,\n",
       " 0.40070706605911255,\n",
       " 0.08105812966823578,\n",
       " 0.7070112228393555,\n",
       " 0.3245834410190582,\n",
       " 0.6371434330940247,\n",
       " 0.5859260559082031,\n",
       " 0.7214884757995605,\n",
       " 0.6194947957992554,\n",
       " 1.2890911102294922,\n",
       " 0.7240879535675049,\n",
       " 0.5007027387619019,\n",
       " 0.22147813439369202]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_logits = batch_end_logits[0].detach().cpu().tolist()\n",
    "end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_and_score [(14, 0.1981472223997116), (24, 0.12966956198215485), (8, 0.129669189453125), (13, 0.03824535012245178), (7, 0.01763373613357544), (12, -0.09021744132041931), (4, -0.11756917834281921), (11, -0.12372050434350967), (23, -0.13106927275657654), (21, -0.14896880090236664), (3, -0.1570422649383545), (15, -0.1992499679327011), (0, -0.23139816522598267), (6, -0.2684593200683594), (16, -0.27217161655426025), (5, -0.3228791654109955), (17, -0.32344263792037964), (1, -0.3325277268886566), (18, -0.39665329456329346), (22, -0.4176713228225708), (19, -0.43190065026283264), (10, -0.4350026547908783), (2, -0.4690726101398468), (9, -0.5479621291160583), (20, -0.5689064264297485)]\n",
      "index_and_score [(21, 1.2890911102294922), (7, 0.9626365900039673), (22, 0.7240879535675049), (19, 0.7214884757995605), (9, 0.7128044366836548), (15, 0.7070112228393555), (17, 0.6371434330940247), (3, 0.6202974319458008), (20, 0.6194947957992554), (0, 0.597241997718811), (18, 0.5859260559082031), (2, 0.5503278970718384), (10, 0.519715428352356), (6, 0.5127164125442505), (23, 0.5007027387619019), (1, 0.4694574177265167), (5, 0.4575151801109314), (11, 0.4107130169868469), (13, 0.40070706605911255), (16, 0.3245834410190582), (4, 0.31571725010871887), (12, 0.22277796268463135), (24, 0.22147813439369202), (8, 0.22147777676582336), (14, 0.08105812966823578)]\n",
      "start_indexes [14, 24, 8, 13, 7, 12, 4, 11, 23, 21, 3, 15, 0, 6, 16, 5, 17, 1, 18, 22]\n",
      "end_indexes [21, 7, 22, 19, 9, 15, 17, 3, 20, 0, 18, 2, 10, 6, 23, 1, 5, 11, 13, 16]\n"
     ]
    }
   ],
   "source": [
    "start_indexes = get_best_indexes( start_logits, n_best_size)\n",
    "end_indexes = get_best_indexes(end_logits, n_best_size)\n",
    "\n",
    "\n",
    "print('start_indexes',start_indexes)\n",
    "print('end_indexes',end_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_text ['[CLS]', '明', '天', '天', '气', '怎', '么', '样', '[SEP]', '明', '天', '天', '气', '不', '错', '我', '们', '不', '如', '一', '起', '出', '去', '吧', '[SEP]']\n",
      "预测结果 ['明', '天']\n",
      "预测结果 ['错', '我', '们', '不', '如', '一', '起']\n",
      "key <function <lambda> at 0x7f55331170d0>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 1.2890911102294922\n",
      "预测结果 ['错', '我', '们', '不', '如', '一', '起', '出']\n",
      "key <function <lambda> at 0x7f5533117ea0>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.7240879535675049\n",
      "预测结果 ['错', '我', '们', '不', '如']\n",
      "key <function <lambda> at 0x7f5533117d08>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.7214884757995605\n",
      "预测结果 ['错']\n",
      "key <function <lambda> at 0x7f5533117950>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.7070112228393555\n",
      "预测结果 ['错', '我', '们']\n",
      "key <function <lambda> at 0x7f5533117048>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.6371434330940247\n",
      "预测结果 ['错', '我', '们', '不', '如', '一']\n",
      "key <function <lambda> at 0x7f5533117a60>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.6194947957992554\n",
      "预测结果 ['错', '我', '们', '不']\n",
      "key <function <lambda> at 0x7f55331179d8>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.5859260559082031\n",
      "预测结果 ['错', '我', '们', '不', '如', '一', '起', '出', '去']\n",
      "key <function <lambda> at 0x7f5533117f28>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.5007027387619019\n",
      "预测结果 ['错', '我']\n",
      "key <function <lambda> at 0x7f5533117598>\n",
      "start_logits 0.1981472223997116\n",
      "end_logits 0.3245834410190582\n"
     ]
    }
   ],
   "source": [
    "print('tokenized_text',tokenized_text)\n",
    "\n",
    "text = tokenized_text[1:3]\n",
    "print('预测结果',text)\n",
    "max_answer_length=20\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # We could hypothetically create invalid predictions, e.g., predict\n",
    "        # that the start of the span is in the question. We throw out all\n",
    "        # invalid predictions.\n",
    "                    \n",
    "#         print('*'*20)\n",
    "#         print('start_index',start_index)\n",
    "#         print('end_index',end_index)\n",
    "        start= int(start_index)\n",
    "        end =int(end_index)\n",
    "        if start > end:\n",
    "#             print('不合适')\n",
    "            continue\n",
    "        if start < len_line_1 :\n",
    "#             print('不合适')\n",
    "            continue\n",
    "\n",
    "        if end_index >= len(tokenized_text):\n",
    "            continue\n",
    "#         if start_index not in feature.token_to_orig_map:\n",
    "#             continue\n",
    "#         if end_index not in feature.token_to_orig_map:\n",
    "#             continue\n",
    "#         if not feature.token_is_max_context.get(start_index, False):\n",
    "#             continue\n",
    "#         if end_index < start_index:\n",
    "#             continue\n",
    "        length = end_index - start_index + 1\n",
    "        if length > max_answer_length:\n",
    "            continue\n",
    "        else:\n",
    "            if start_logits[start]<0:\n",
    "                continue\n",
    "            if start_logits[start]<0.1:\n",
    "                continue\n",
    "            if end_logits[end]<0:\n",
    "                continue\n",
    "            if end_logits[end]<0.1:\n",
    "                continue\n",
    "            text = tokenized_text[start:end]\n",
    "            print('预测结果',text)\n",
    "            key=lambda x: (x.start_logits[start] + x.start_logits[start])\n",
    "            print(\"key\",key)\n",
    "            \n",
    "            print(\"start_logits\",start_logits[start])\n",
    "            print(\"end_logits\",end_logits[end])\n",
    "            \n",
    "\n",
    "        \n",
    "#         if start_index >= len(indexed_tokens):\n",
    "#             continue\n",
    "#         if end_index >= len(indexed_tokens):\n",
    "#             continue\n",
    "#         if start_index not in feature.token_to_orig_map:\n",
    "#             continue\n",
    "#         if end_index not in feature.token_to_orig_map:\n",
    "#             continue\n",
    "#         if not feature.token_is_max_context.get(start_index, False):\n",
    "#             continue\n",
    "#         if end_index < start_index:\n",
    "#             continue\n",
    "#         length = end_index - start_index + 1\n",
    "#         if length > max_answer_length:\n",
    "#             continue\n",
    "#         prelim_predictions.append(\n",
    "#             _PrelimPrediction(\n",
    "#                 feature_index=feature_index,\n",
    "#                 start_index=start_index,\n",
    "#                 end_index=end_index,\n",
    "#                 start_logit=result.start_logits[start_index],\n",
    "#                 end_logit=result.end_logits[end_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2047, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_start_logits[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
